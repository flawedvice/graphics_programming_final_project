
 -------------------- base.js ------------------------ 

/**
 * Captures a picture from a video.
 * @param {*} capture
 * @returns img object
 */
function takePicture(capture) {
	if (!img) {
		img = createImage(capture.width, capture.height);
	}
	img.copy(
		capture,
		0,
		0,
		capture.width,
		capture.height,
		0,
		0,
		img.width,
		img.height
	);
	return img;
}

 -------------------- filters.js ------------------------ 

/**
 *
 * @param {*} img
 * @returns Filtered image
 */
function invertFilter(img) {
	const inverted = createImage(img.width, img.height);

	inverted.loadPixels();
	img.loadPixels();

	let index = 0,
		red = 0,
		green = 0,
		blue = 0,
		alpha = 0;

	for (let x = 0; x < img.width; x++) {
		for (let y = 0; y < img.height; y++) {
			index = (y * img.width + x) * 4;

			// Access original pixels
			red = img.pixels[index + 0];
			green = img.pixels[index + 1];
			blue = img.pixels[index + 2];
			alpha = img.pixels[index + 3];

			// Replace inverted pixels into new image
			inverted.pixels[index + 0] = 255 - red;
			inverted.pixels[index + 1] = 255 - green;
			inverted.pixels[index + 2] = 255 - blue;
			inverted.pixels[index + 3] = alpha;
		}
	}
	inverted.updatePixels();
	return inverted;
}

/**
 * @param {*} img
 * @returns Filtered image
 */
function grayscaleFilter(img) {
	const grayscale = createImage(img.width, img.height);

	grayscale.loadPixels();
	img.loadPixels();

	let index = 0,
		red = 0,
		green = 0,
		blue = 0,
		alpha = 0;

	// Add 20% of brightness
	const brightness = 1.2;

	for (let x = 0; x < img.width; x++) {
		for (let y = 0; y < img.height; y++) {
			index = (y * img.width + x) * 4;

			// Access original pixels
			red = img.pixels[index + 0];
			green = img.pixels[index + 1];
			blue = img.pixels[index + 2];
			alpha = img.pixels[index + 3];

			// Compute average value
			let avg = (red + green + blue) / 3;

			// Add 20% of brightness to average, controlling intensity
			avg *= brightness;
			if (avg > 255) avg = 255;

			// Replace grayscale pixels into new image
			grayscale.pixels[index + 0] = avg;
			grayscale.pixels[index + 1] = avg;
			grayscale.pixels[index + 2] = avg;
			grayscale.pixels[index + 3] = alpha;
		}
	}

	grayscale.updatePixels();
	return grayscale;
}

/**
 *
 * @param {*} img
 * @param {'red'|'green'|'blue'} channel
 * @param {number} threshold
 * @returns Filtered image
 */
function RGBFilter(img, channel, threshold) {
	const channeled = createImage(img.width, img.height);

	channeled.loadPixels();
	img.loadPixels();

	let index = 0,
		red = 0,
		green = 0,
		blue = 0,
		alpha = 0;

	for (let x = 0; x < img.width; x++) {
		for (let y = 0; y < img.height; y++) {
			index = (y * img.width + x) * 4;

			// Access original pixels
			red = img.pixels[index + 0];
			green = img.pixels[index + 1];
			blue = img.pixels[index + 2];
			alpha = img.pixels[index + 3];

			if (threshold) {
				// Apply threshold to colors
				red = red > threshold ? 255 : 0;
				green = green > threshold ? 255 : 0;
				blue = blue > threshold ? 255 : 0;
			}

			// Replace channeled pixels into new image
			channeled.pixels[index + 0] = channel === "red" ? red : 0;
			channeled.pixels[index + 1] = channel === "green" ? green : 0;
			channeled.pixels[index + 2] = channel === "blue" ? blue : 0;
			channeled.pixels[index + 3] = alpha;
		}
	}

	channeled.updatePixels();
	return channeled;
}

/**
 *
 * @param {*} img
 * @param {'HSV'|'HSI'} colorSpace
 * @param {number} threshold
 * @returns Filtered image
 */
function colorSpaceFilter(img, colorSpace, threshold) {
	const transformed = createImage(img.width, img.height);

	transformed.loadPixels();
	img.loadPixels();

	let index = 0,
		red = 0,
		green = 0,
		blue = 0,
		alpha = 0;

	// Values used in HSV color space transformation
	let max, min, saturation;
	let value;
	let hue;

	// Values used in HSI color space transformation
	let H, S, I, sum;

	// Common values used by previous transformations
	let redPrime, greenPrime, bluePrime;

	for (let x = 0; x < img.width; x++) {
		for (let y = 0; y < img.height; y++) {
			index = (y * img.width + x) * 4;

			// Access original pixels
			red = img.pixels[index + 0];
			green = img.pixels[index + 1];
			blue = img.pixels[index + 2];
			alpha = img.pixels[index + 3];

			/// Compute transformed values
			if (colorSpace === "HSV") {
				// Saturation
				max = Math.max(red, green, blue);
				min = Math.min(red, green, blue);
				saturation = (max - min) / max;

				// Value
				value = max;

				// Normalize RGB channels
				redPrime = (max - red) / (max - min);
				greenPrime = (max - green) / (max - min);
				bluePrime = (max - blue) / (max - min);

				// Hue
				if (saturation === 0) hue = 0;
				else {
					if (red === max && green === min) hue = 5 + bluePrime;
					else if (red === max && green !== min) hue = 1 - greenPrime;
					else if (green === max && blue === min) hue = redPrime + 1;
					else if (green === max && blue !== min) hue = 3 - bluePrime;
					else if (red === max) hue = 3 + greenPrime;
					else hue = 5 - redPrime;
				}
				hue *= 60;

				// Apply threshold to colors if needed
				if (threshold) {
					hue = hue > threshold ? 255 : 0;
					saturation = saturation > threshold ? 255 : 0;
					value = value > threshold ? 255 : 0;
				}

				// Replace filtered pixels into new image
				transformed.pixels[index + 0] = hue;
				transformed.pixels[index + 1] = saturation;
				transformed.pixels[index + 2] = value;
			} else if (colorSpace === "HSI") {
				// Compute CMY color space
				sum = red + green + blue;
				I = sum / 3;
				S = 1 - (3 / sum) * Math.min(red, green, blue);
				H = Math.acos(
					(0.5 * (red - green) + (red - blue)) /
						Math.pow(
							Math.pow(red - green, 2) +
								(red - blue) * (green - blue),
							0.5
						)
				);

				if (S === 0) H = 0;
				if (blue / I > green / I) H = 360 - H;

				// Apply threshold to colors if needed
				if (threshold) {
					H = H > threshold ? 255 : 0;
					S = S > threshold ? 255 : 0;
					I = I > threshold ? 255 : 0;
				}

				// Replace filtered pixels into new image
				transformed.pixels[index + 0] = H;
				transformed.pixels[index + 1] = S;
				transformed.pixels[index + 2] = I;
			} else {
				transformed.pixels[index + 0] = red;
				transformed.pixels[index + 1] = green;
				transformed.pixels[index + 2] = blue;
			}

			// Every transformation keeps the image's alpha value
			transformed.pixels[index + 3] = alpha;
		}
	}

	transformed.updatePixels();
	return transformed;
}

/**
 *
 * @param {*} img
 * @param {number} level Blur level
 * @returns Filtered image
 */
function blurFilter(img, level) {
	const blurred = createImage(img.width, img.height);

	blurred.loadPixels();
	img.loadPixels();

	let index = 0,
		red = 0,
		green = 0,
		blue = 0,
		alpha = 0;

	// Create a dynamic kernel based on level of blur
	const baseArray = new Array(level).fill(1 / pow(level, 2));
	const kernel = new Array(level).fill(baseArray);

	// Convolution results array
	let c = [];

	for (let x = 0; x < img.width; x++) {
		for (let y = 0; y < img.height; y++) {
			index = (y * img.width + x) * 4;

			// Access original pixels
			red = img.pixels[index + 0];
			green = img.pixels[index + 1];
			blue = img.pixels[index + 2];
			alpha = img.pixels[index + 3];

			// Store convolution results
			c = convolution(x, y, kernel, img);

			// Replace blurred pixels into new image
			blurred.pixels[index + 0] = c[0]; //red;
			blurred.pixels[index + 1] = c[1]; //green;
			blurred.pixels[index + 2] = c[2]; //blue;
			blurred.pixels[index + 3] = alpha; //255;
		}
	}

	blurred.updatePixels();
	return blurred;
}

/**
 *
 * @param {*} img
 * @returns Filtered image
 */
function pixelatedFilter(img) {
	// First, set image to grayscale
	const pixelated = grayscaleFilter(img);

	// Split image into blocks of 5x5 pixels
	const blockSize = 5,
		blocks = [];
	let pixels = [];

	let index = 0,
		red = 0,
		green = 0,
		blue = 0,
		alpha = 0;

	for (let x = 0; x < img.width; x += blockSize) {
		for (let y = 0; y < img.width; y += blockSize) {
			// For every block
			pixels = [];
			for (let i = 0; i < blockSize; i++) {
				for (let j = 0; j < blockSize; j++) {
					index = (x + i + (y + j) * img.width) * 4;

					red = img.pixels[index + 0];
					green = img.pixels[index + 1];
					blue = img.pixels[index + 2];
					alpha = img.pixels[index + 3];

					// Save both RGBA channels and the pixel index for easy re-mapping
					pixels.push({
						idx: index,
						channels: [red, green, blue, alpha],
					});
				}
			}
			blocks.push(pixels);
		}
	}

	// Compute average pixel intensity of blocks
	let avgRed, avgGreen, avgBlue, avgAlpha;
	const blocksAvg = [];
	for (const block of blocks) {
		avgRed = 0;
		avgGreen = 0;
		avgBlue = 0;
		avgAlpha = 0;
		for (const pixels of block) {
			avgRed += pixels.channels[0];
			avgGreen += pixels.channels[1];
			avgBlue += pixels.channels[2];
			avgAlpha += pixels.channels[3];
		}
		avgRed = Math.round(avgRed / block.length);
		avgGreen = Math.round(avgGreen / block.length);
		avgBlue = Math.round(avgBlue / block.length);
		avgAlpha = Math.round(avgAlpha / block.length);

		blocksAvg.push({
			indices: block.map((pixels) => pixels.idx),
			avgChannels: [avgRed, avgGreen, avgBlue, avgAlpha],
		});
	}

	// Paint the image using average intensities
	let pixelRed, pixelGreen, pixelBlue, pixelAlpha;

	for (const block of blocksAvg) {
		pixelRed = block.avgChannels[0];
		pixelGreen = block.avgChannels[1];
		pixelBlue = block.avgChannels[2];
		pixelAlpha = block.avgChannels[3];

		block.indices.forEach((idx) => {
			pixelated.pixels[idx + 0] = pixelRed;
			pixelated.pixels[idx + 1] = pixelGreen;
			pixelated.pixels[idx + 2] = pixelBlue;
			pixelated.pixels[idx + 3] = pixelAlpha;
		});
	}

	pixelated.updatePixels();
	return pixelated;
}

 -------------------- sketch.js ------------------------ 

/*
	COMMENTARY
	------------------------------------------------------------------------------------------------

	# Findings:
	This was my first time working with color spaces, which I found quite challenging to work with. I didn't know all the math that was behind implementing color space transformations, along with how many schemes or "spaces" were there.

	# Approach:
	I found that an Object Oriented Programming approach would suit this project pretty well, as I would need shared properties for every widget (inheritance) and would therefore allow me to reuse code blocks. The, for every filter I could create a reusable function too. Along with this organization, I decided to separate the code into different files, storing related code blocks together.

	# Problems found:
	The first problem was getting my head around the organization of pixels inside an image object. The logic behind the iteration over every set of RGB(a) pixels needed to be refactored several times.

	Another issue I had was developing the pixelated filter. What I found complicated about it was mapping the averaged pixels back to a full-size image. After some testing, I found a clever approach: I could save every pixel's index at the moment of reading the values from the original image. This way, I could just copy the averaged values over the stored indices, which in turn solved my problem.

	# About the project's success
	I think I did manage to do every task at least to a good degree. I would have liked to have spent more time developing this project, but as it wasn't possible, I'm happy with the result.

	# About the extension
	I thought that I couldn't finish this project without further testing the capabilities of the ml5js library, and 3 factors made me decide to implement a live face filter:
	- The reduced size of the image would allow me to implement real-time filtering.
	- The faceMesh API is well enough documented for me to learn to use it in a short time.
	- Every filter and widget processed and displayed, respectively, only static images, so this one needed to be different.
	I thought that would be interesting to replace different parts of my face to build a dynamic new face, so I chose the Japanese Daruma as a model. I managed to replace my whole face, eyes, nose, and mouth independently while allowing the real-time positioning of every element to follow my face.
 */

// Image and video variables
let capture,
	img,
	ready = false;

// Face detection variables
let faceMesh,
	faces = [],
	liveFaces = [];

// Widgets variable
let widgets;

function preload() {
	// Use sample image took using this program (keyReleased function)
	img = loadImage("samples/image.png");

	// Start capturing the video
	capture = createCapture(VIDEO);
	capture.hide();
	capture.elt.addEventListener("playing", () => (ready = true));

	// Instantiate faceMesh
	faceMesh = ml5.faceMesh({
		maxFaces: 1,
		refineLandmarks: false,
		flipHorizontal: false,
	});
}

function setup() {
	// Basix canvas and image configuration
	createCanvas(1200, 900);
	pixelDensity(1);

	// Resize both image and video
	img.resize(160, 120);
	capture.size(160, 120);

	// Instantiate widgets array
	widgets = [
		// 0.- Original
		new Widget("Webcam image", img, 0, 0),
		// 1.- Grayscale + 20% brightness
		new Widget(
			"Grayscale + brightness",
			grayscaleFilter(img),
			img.width,
			0
		),
		// 2.- Red Channel
		new ColorWidget("Red", img, 0, img.height, "red"),
		// 3.- Green Channel
		new ColorWidget("Green", img, img.width, img.height, "green"),
		// 4.- Blue Channel
		new ColorWidget("Blue", img, img.width * 2, img.height, "blue"),
		// 5.- Red Channel with Threshold
		new ColorWidget("Red + control", img, 0, img.height * 2, "red", true),
		// 6.- Green Channel with Threshold
		new ColorWidget(
			"Green + control",
			img,
			img.width,
			img.height * 2,
			"green",
			true
		),
		// 7.- Blue Channel with Threshold
		new ColorWidget(
			"Blue + control",
			img,
			img.width * 2,
			img.height * 2,
			"blue",
			true
		),
		// 8.- Repeat original
		new Widget("Repeat original", img, 0, img.height * 3),
		// 9.- Color Space 1 (HSV)
		new ColorSpaceWidget(
			"Color Space (HSV)",
			img,
			img.width,
			img.height * 3,
			"HSV"
		),
		// 10.- Color Space 2 (HSI)
		new ColorSpaceWidget(
			"Color Space (HSI)",
			img,
			img.width * 2,
			img.height * 3,
			"HSI"
		),
		// 11.- Face detection. `null` until face detection is enabled
		null,
		// 12.- Color Space 1 (HSV) with Threshold
		new ColorSpaceWidget(
			"Color Space (HSV) + control",
			img,
			img.width,
			img.height * 4,
			"HSV",
			true
		),
		// 13.- Color Space 2 (HSI) with Threshold
		new ColorSpaceWidget(
			"Color Space (HSI) + control",
			img,
			img.width * 2,
			img.height * 4,
			"HSI",
			true
		),
		// 14.- Custom Filter Widget
		new LiveFaceDetectionWidget(
			capture,
			"Daruma",
			img,
			img.width * 2,
			0,
			liveFaces[0]
		),
	];

	// Detect and add face filters
	// Image face
	faceMesh.detect(img, (results, error) => {
		if (results) {
			faces = results;
			widgets[11] = new FaceDetectionWidget(
				"Face detection",
				img,
				0,
				img.height * 4,
				null,
				faces[0]
			);
		}
		if (error) {
			console.log(error);
			return;
		}
	});

	// Live face
	faceMesh.detectStart(capture, (results, error) => {
		if (results) {
			liveFaces = results;
		}
		if (error) {
			console.log(error);
			return;
		}
	});
}

function draw() {
	// Set a clear background
	background(245, 245, 245);

	if (img && widgets) {
		// Update Live Face Detection on every tick
		widgets[14] = new LiveFaceDetectionWidget(
			capture,
			"Daruma",
			img,
			img.width * 2,
			0,
			liveFaces[0]
		);

		// Draw every widget's image
		for (const widget of widgets) {
			if (widget) widget.draw();
		}
	} else {
		// Use to take picture and later replace in `samples/image.png`
		image(capture, 0, 0, w * 2, h * 2);
	}
}

function keyReleased() {
	// Used to take sample picture
	if (keyCode === 32 && ready) {
		img = takePicture(capture);
		faceMesh.detect(img.canvas, (results) => (faces = results));
		ready = false;
	}

	// Enables face filter switch
	switch (key) {
		case "1":
			// keystroke "1"
			widgets[11] = new FaceDetectionWidget(
				"Face detection: grayscale",
				img,
				0,
				img.height * 4,
				"grayscale",
				faces[0]
			);
			break;
		case "2":
			// keystroke "2"
			widgets[11] = new FaceDetectionWidget(
				"Face detection: blur",
				img,
				0,
				img.height * 4,
				"blur",
				faces[0]
			);
			break;
		case "3":
			// keystroke "3"
			widgets[11] = new FaceDetectionWidget(
				"Face detection: colorSpace",
				img,
				0,
				img.height * 4,
				"colorSpace",
				faces[0]
			);
			break;
		case "4":
			// keystroke "4"
			widgets[11] = new FaceDetectionWidget(
				"Face detection: pixelated",
				img,
				0,
				img.height * 4,
				"pixelated",
				faces[0]
			);
			break;
		case "5":
			// keystroke "5"
			widgets[11] = new FaceDetectionWidget(
				"Face detection: inverted",
				img,
				0,
				img.height * 4,
				"inverted",
				faces[0]
			);
			break;
		case "6":
			// keystroke "6"
			widgets[11] = new FaceDetectionWidget(
				"Face detection: none",
				img,
				0,
				img.height * 4,
				null,
				faces[0]
			);
			break;
	}
}

 -------------------- utils.js ------------------------ 

/**
 * Convolution function used in blur filter
 * @param {number} x
 * @param {number} y
 * @param {number[][]} kernel NxN matrix
 * @param {*} img
 * @returns RGB colors
 */
function convolution(x, y, kernel, img) {
	let totalRed = 0,
		totalGreen = 0,
		totalBlue = 0;

	const offset = floor(kernel.length / 2);

	let xLoc, yLoc, index;

	for (let i = 0; i < kernel.length; i++) {
		for (let j = 0; j < kernel.length; j++) {
			xLoc = x + i - offset;
			yLoc = y + j - offset;

			index = (img.width * yLoc + xLoc) * 4;
			index = constrain(index, 0, img.pixels.length - offset);

			totalRed += img.pixels[index + 0] * kernel[i][j];
			totalGreen += img.pixels[index + 1] * kernel[i][j];
			totalBlue += img.pixels[index + 2] * kernel[i][j];
		}
	}

	return [totalRed, totalGreen, totalBlue];
}

 -------------------- widget.js ------------------------ 

/**
 * Simple widget that display an image and a title.
 *
 * The image can be previously filtered.
 */
class Widget {
	/**
	 *
	 * @param {string} title
	 * @param {*} img
	 * @param {number} x
	 * @param {number} y
	 */
	constructor(title, img, x, y) {
		this.title = title;
		this.img = img;
		this.x = x;
		this.y = y;
	}

	drawTitle() {
		push();
		fill(255, 255, 255);
		rect(this.x, this.y, this.img.width, 20);
		textAlign(LEFT);
		fill(0, 0, 0);
		text(this.title, this.x + 4, this.y + 14);
		pop();
	}

	draw() {
		image(this.img, this.x, this.y);

		this.drawTitle();
	}
}

/**
 * Shows image with only one color channel (R,G, or B).
 *
 * Can be drawn with a threshold control.
 */
class ColorWidget extends Widget {
	/**
	 *
	 * @param {string} title
	 * @param {*} img
	 * @param {number} x
	 * @param {number} y
	 * @param {'red'|'green'|'blue'} color
	 * @param {boolean} useTreshold
	 */
	constructor(title, img, x, y, color, useTreshold = false) {
		super(title, img, x, y);
		this.color = color;
		this.useTreshold = useTreshold;

		this.thresholdSlider = null;

		if (this.useTreshold) {
			this.thresholdSlider = createSlider(0, 255, 125);
			this.thresholdSlider.position(
				this.x,
				this.y + this.img.height - 20
			);
		}
	}

	draw() {
		if (this.useTreshold && this.thresholdSlider) {
			image(
				RGBFilter(this.img, this.color, this.thresholdSlider.value()),
				this.x,
				this.y
			);
		} else {
			image(RGBFilter(this.img, this.color, null), this.x, this.y);
		}

		this.drawTitle();
	}
}

/**
 * Shows image after transforming it into another color space.
 *
 * Can be drawn with a threshold control.
 */
class ColorSpaceWidget extends Widget {
	/**
	 *
	 * @param {string} title
	 * @param {*} img
	 * @param {number} x
	 * @param {number} y
	 * @param {'HSV'|'HSI'} colorSpace
	 * @param {boolean} useTreshold
	 */
	constructor(title, img, x, y, colorSpace, useTreshold = false) {
		super(title, img, x, y);
		this.colorSpace = colorSpace;
		this.useTreshold = useTreshold;

		this.thresholdSlider = null;

		if (this.useTreshold) {
			this.thresholdSlider = createSlider(0, 255, 125);
			this.thresholdSlider.position(
				this.x,
				this.y + this.img.height - 20
			);
		}
	}

	draw() {
		if (this.useTreshold && this.thresholdSlider) {
			image(
				colorSpaceFilter(
					this.img,
					this.colorSpace,
					this.thresholdSlider.value()
				),
				this.x,
				this.y
			);
		} else {
			image(
				colorSpaceFilter(this.img, this.colorSpace, null),
				this.x,
				this.y
			);
		}

		this.drawTitle();
	}
}

/**
 * Shows image and applies a face filter on top.
 */
class FaceDetectionWidget extends Widget {
	/**
	 *
	 * @param {string} title
	 * @param {*} img
	 * @param {number} x
	 * @param {number} y
	 * @param {'grayscale'|'colorSpace'|'inverted'|'blur'|'pixelated'|null} filter
	 * @param {*} face
	 */
	constructor(title, img, x, y, filter, face) {
		super(title, img, x, y);

		this.face = face;
		this.box = {
			x: this.face ? Math.floor(this.face.box.xMin) : 0,
			y: this.face ? Math.floor(this.face.box.yMin) : 0,
			w: this.face ? Math.ceil(this.face.box.width) : 0,
			h: this.face ? Math.ceil(this.face.box.height) : 0,
		};

		// Crop image using bounding box
		this.croppedImg = this.face ? this.crop(this.img, this.box) : this.img;

		// Filter cropped image
		this.filter = filter;
		switch (this.filter) {
			case "grayscale":
				this.filteredImg = grayscaleFilter(this.croppedImg);
				break;
			case "colorSpace":
				this.filteredImg = colorSpaceFilter(
					this.croppedImg,
					"HSV",
					null
				);
				break;
			case "inverted":
				this.filteredImg = invertFilter(this.croppedImg);
				break;
			case "blur":
				const blurLevel = 10; // Enough to make unrecognizable
				this.filteredImg = blurFilter(this.croppedImg, blurLevel);
				break;
			case "pixelated":
				this.filteredImg = pixelatedFilter(
					this.croppedImg,
					this.x,
					this.y
				);
				break;
			default:
				this.filteredImg = this.croppedImg;
		}
	}

	async draw() {
		// Draw image...
		image(this.img, this.x, this.y);

		if (this.filter) {
			// Filtered and cropped image
			image(this.filteredImg, this.x, this.y);
		} else {
			// Bounding box
			push();
			noFill();
			strokeWeight(2);
			stroke(0, 250, 0);
			rect(
				this.x + this.box.x,
				this.y + this.box.y,
				this.box.w,
				this.box.h
			);
			pop();
		}

		// Draw extra instructions
		push();
		fill(255, 255, 255);
		rect(this.x, this.y + this.img.height - 20, this.img.width, 20);
		textAlign(LEFT);
		fill(0, 0, 0);
		text("Try keys from 1 to 6", this.x + 4, this.y + this.img.height - 8);
		pop();

		this.drawTitle();
	}

	crop(img, box) {
		const cropped = createImage(img.width, img.height);

		cropped.loadPixels();
		img.loadPixels();

		let index,
			red = 0,
			green = 0,
			blue = 0,
			alpha = 0;

		const rightLimit = box.x + box.w,
			bottomLimit = box.y + box.h;
		for (let x = box.x; x < rightLimit; x++) {
			for (let y = box.y; y < bottomLimit; y++) {
				// Access original pixels
				index = (y * img.width + x) * 4;

				red = img.pixels[index + 0];
				green = img.pixels[index + 1];
				blue = img.pixels[index + 2];
				alpha = img.pixels[index + 3];

				// Access cropped pixels
				cropped.pixels[index + 0] = red;
				cropped.pixels[index + 1] = green;
				cropped.pixels[index + 2] = blue;
				cropped.pixels[index + 3] = alpha;
			}
		}

		cropped.updatePixels();
		return cropped;
	}
}

/**
 * Shows live video and applies a face filter on top.
 */
class LiveFaceDetectionWidget extends Widget {
	/**
	 *
	 * @param {*} capture
	 * @param {string} title
	 * @param {*} img
	 * @param {number} x
	 * @param {number} y
	 * @param {*} face
	 */
	constructor(capture, title, img, x, y, face) {
		super(title, img, x, y);

		this.capture = capture;
		this.face = face;
	}

	async draw() {
		// Draw capture as image
		image(this.capture, this.x, this.y);

		if (this.face) {
			this.drawOval();

			this.drawEyes();

			this.drawMouth();
		}

		this.drawTitle();
	}

	drawOval() {
		push();
		noStroke();
		ellipseMode(CENTER);
		fill(255, 0, 0);
		let centerX = this.x + this.face.faceOval.centerX,
			centerY = this.face.faceOval.centerY,
			faceWidth = this.face.faceOval.width * 1.4,
			faceHeight = this.face.faceOval.height;
		ellipse(centerX, centerY, faceWidth);
		fill(250, 250, 250);
		ellipse(centerX, centerY, faceWidth * 0.9);
		pop();
	}

	drawEyes() {
		push();
		noStroke();
		ellipseMode(CENTER);

		// Left Eye
		let centerXLeft = this.x + this.face.leftEye.centerX + 4,
			centerYLeft = this.face.leftEye.centerY + 4,
			eyeRadiusLeft = this.face.leftEye.width * 2;

		// Lid
		fill(253, 224, 71);
		ellipse(centerXLeft, centerYLeft, eyeRadiusLeft);
		// Sclera
		fill(250, 250, 250);
		ellipse(centerXLeft, centerYLeft, eyeRadiusLeft * 0.8);
		// Iris
		fill(50, 50, 50);
		ellipse(centerXLeft, centerYLeft, eyeRadiusLeft * 0.6);
		// Eyebrow
		noFill();
		strokeWeight(2);
		stroke(50, 50, 50);
		arc(
			centerXLeft,
			centerYLeft,
			eyeRadiusLeft * 1.3,
			eyeRadiusLeft * 1.3,
			PI + QUARTER_PI,
			QUARTER_PI,
			OPEN
		);

		noStroke();
		// Right Eye
		let centerXRight = this.x + this.face.rightEye.centerX - 4,
			centerYRight = this.face.rightEye.centerY + 4,
			eyeRadiusRight = this.face.rightEye.width * 2;
		// Lid
		fill(253, 224, 71);
		ellipse(centerXRight, centerYRight, eyeRadiusRight);
		// Sclera
		fill(250, 250, 250);
		ellipse(centerXRight, centerYRight, eyeRadiusRight * 0.8);
		// Iris
		fill(50, 50, 50);
		ellipse(centerXRight, centerYRight, eyeRadiusRight * 0.6);
		// Eyebrow
		noFill();
		strokeWeight(2);
		stroke(50, 50, 50);
		arc(
			centerXRight,
			centerYRight,
			eyeRadiusRight * 1.3,
			eyeRadiusRight * 1.3,
			PI - QUARTER_PI,
			TWO_PI - QUARTER_PI,
			OPEN
		);

		pop();
	}

	drawMouth() {
		push();
		noStroke();
		ellipseMode(CENTER);

		/// Nose
		// Shadow
		let centerNoseX = this.x + this.face.lips.centerX,
			centerNoseY = this.face.lips.centerY - 4,
			widthNose = this.face.lips.width * 1.5,
			heightNose = 2;

		fill(218, 197, 183);
		ellipse(centerNoseX, centerNoseY, widthNose, heightNose);

		// Nasals
		noFill();
		strokeWeight(1);
		stroke(255, 0, 0);
		arc(
			centerNoseX - widthNose / 4,
			centerNoseY,
			widthNose / 3,
			(widthNose / 3) * 1.3,
			PI,
			0,
			OPEN
		);
		arc(
			centerNoseX + widthNose / 4,
			centerNoseY,
			widthNose / 3,
			(widthNose / 3) * 1.3,
			PI,
			0,
			OPEN
		);

		/// Mouth
		// Lips
		arc(centerNoseX, centerNoseY + 6, widthNose * 1.2, 4, PI, 0, OPEN);
		// Left Shadow
		noFill();
		strokeWeight(3);
		stroke(50, 50, 50);
		arc(
			centerNoseX + widthNose * 0.65,
			centerNoseY + 4,
			widthNose * 0.4,
			widthNose * 0.4,
			PI + QUARTER_PI,
			PI - QUARTER_PI,
			OPEN
		);
		// Right Shadow
		arc(
			centerNoseX - widthNose * 0.65,
			centerNoseY + 4,
			widthNose * 0.4,
			widthNose * 0.4,
			QUARTER_PI,
			TWO_PI - QUARTER_PI,
			OPEN
		);

		/// Bottom Shadows
		// Bottom Left Shadow
		arc(
			centerNoseX - widthNose * 0.3,
			centerNoseY + 14,
			widthNose * 0.4,
			widthNose * 0.4,
			-QUARTER_PI,
			PI - QUARTER_PI,
			OPEN
		);
		// Bottom Center Shadow
		line(
			centerNoseX,
			centerNoseY + 10,
			centerNoseX,
			centerNoseY + 10 + widthNose * 0.4
		);
		// Bottom Right Shadow
		arc(
			centerNoseX + widthNose * 0.3,
			centerNoseY + 14,
			widthNose * 0.4,
			widthNose * 0.4,
			QUARTER_PI,
			PI + QUARTER_PI,
			OPEN
		);
		pop();
	}

	/**
	 *
	 * @param {{x:number, y:number}} keypoints
	 * @returns
	 */
	mapKeypoints(keypoints) {
		const x = map(
			keypoints.x,
			0,
			width,
			this.face.box.xMin,
			this.face.box.xMax
		);
		const y = keypoints.y;
		return { x, y };
	}
}
/* class PixelatedWidget extends Widget {
	constructor(img, x, y) {
		super(img, x, y);
	}

	draw() {
		image(this.img, this.x, this.y);
		pixelatedFilter(this.img, this.x, this.y, 4);
	}
} */
